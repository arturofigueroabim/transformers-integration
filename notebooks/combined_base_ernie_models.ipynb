{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac2d56b-234a-45b4-998e-a01896768628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/afigueroa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d56ea8f3-d884-4587-af45-b9c4b647e864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">transformers</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> AutoModel, AutoConfig                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tfIntegration.baseModel.models.base</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> BaseClassificationModel                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">tfIntegration.baseModel.training.module</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> ClassificationModule                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torch</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">torch.nn</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">nn</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pytorch_lightning</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pl</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/afigueroa/tfIntegration/baseModel/training/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">config</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> CONFIG                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 2 <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">processing.datasets</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> RelationDataset                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">os</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>os.environ[<span style=\"color: #808000; text-decoration-color: #808000\">\"TOKENIZERS_PARALLELISM\"</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">\"false\"</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ModuleNotFoundError: </span>No module named <span style=\"color: #008000; text-decoration-color: #008000\">'processing'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mtransformers\u001b[0m \u001b[94mimport\u001b[0m AutoModel, AutoConfig                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mtfIntegration\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mbaseModel\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmodels\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mbase\u001b[0m \u001b[94mimport\u001b[0m BaseClassificationModel                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[94mfrom\u001b[0m \u001b[4;96mtfIntegration\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mbaseModel\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mtraining\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mmodule\u001b[0m \u001b[94mimport\u001b[0m ClassificationModule                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtorch\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mtorch\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mnn\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mnn\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mpytorch_lightning\u001b[0m \u001b[94mas\u001b[0m \u001b[4;96mpl\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/afigueroa/tfIntegration/baseModel/training/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m2\u001b[0m in \u001b[92m<module>\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96mconfig\u001b[0m \u001b[94mimport\u001b[0m CONFIG                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 2 \u001b[94mfrom\u001b[0m \u001b[4;96mprocessing\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mdatasets\u001b[0m \u001b[94mimport\u001b[0m RelationDataset                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mos\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mos.environ[\u001b[33m\"\u001b[0m\u001b[33mTOKENIZERS_PARALLELISM\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[33m\"\u001b[0m\u001b[33mfalse\u001b[0m\u001b[33m\"\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mModuleNotFoundError: \u001b[0mNo module named \u001b[32m'processing'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "from tfIntegration.baseModel.models.base import BaseClassificationModel\n",
    "from tfIntegration.baseModel.training.module import ClassificationModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b9b9a8d-816c-4db6-a64d-de2d8207bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig\n",
    "from tfIntegration.baseModel.models.base import BaseClassificationModel\n",
    "from tfIntegration.baseModel.training.module import ClassificationModule\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, base_model_checkpoint, ernie_model_path, dropout=0.05, n_classes=2):\n",
    "        super(CombinedModel, self).__init__()\n",
    "\n",
    "        # Load the PyTorch trained base model\n",
    "        self.base_model = BaseClassificationModel() # Initialize your base model class\n",
    "        checkpoint = torch.load(base_model_checkpoint) # Load the PyTorch checkpoint\n",
    "        self.base_model.load_state_dict(checkpoint['state_dict']) # Load the state dict into your base model\n",
    "\n",
    "\n",
    "        # Load the pre-trained ERNIE model\n",
    "        ernie_config = AutoConfig.from_pretrained(ernie_model_path)\n",
    "        self.ernie_model = AutoModel.from_pretrained(ernie_model_path, config=ernie_config)\n",
    "\n",
    "        # Set the hidden size based on one of the models\n",
    "        self.hidden_size = ernie_config.hidden_size\n",
    "\n",
    "        # (combined) model classification head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size*2, self.hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(self.hidden_size, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass input through base model\n",
    "        base_output = self.base_model(*x)\n",
    "\n",
    "        # Pass input through ERNIE model\n",
    "        ernie_output = self.ernie_model(*x)\n",
    "\n",
    "        # Concatenate the outputs\n",
    "        combined_output = torch.cat((base_output[0][:, 0, :], ernie_output[0][:, 0, :]), dim=1)\n",
    "\n",
    "        # Pass through final classification head\n",
    "        return self.head(combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8932d589-cba1-4515-8586-38f0898db8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span>base_model_checkpoint = <span style=\"color: #808000; text-decoration-color: #808000\">\"../baseModel/trained_model/base_model.ckpt\"</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>ernie_model_path = <span style=\"color: #808000; text-decoration-color: #808000\">\"./models/\"</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 model = CombinedModel(base_model_checkpoint, ernie_model_path)                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">14</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load the PyTorch trained base model</span>                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">12 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_model = BaseClassificationModel() <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Initialize your base model class</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>checkpoint = torch.load(base_model_checkpoint) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load the PyTorch checkpoint</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>14 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_model.load_state_dict(checkpoint[<span style=\"color: #808000; text-decoration-color: #808000\">'state_dict'</span>]) <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load the state dict </span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Load the pre-trained ERNIE model</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/afigueroa/tfIntegration/.venv/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2041</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state_dict</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2038 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">', '</span>.join(<span style=\"color: #808000; text-decoration-color: #808000\">'\"{}\"'</span>.format(k) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> missing_keys)))               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2039 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2040 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(error_msgs) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2041 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">'Error(s) in loading state_dict for {}:\\n\\t{}'</span>.format(     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2042 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │      </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__class__</span>.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__name__</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\t\"</span>.join(error_msgs)))         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2043 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _IncompatibleKeys(missing_keys, unexpected_keys)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2044 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Error</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in loading state_dict for BaseClassificationModel:\n",
       "        Missing <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">key</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in state_dict: <span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.position_ids\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.word_embeddings.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.position_embeddings.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.token_type_embeddings.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.embeddings.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.0.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.1.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.2.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.3.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.4.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.5.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.6.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.7.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.8.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.attention.output.LayerNorm.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.9.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.query.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.attention.output.LayerNorm.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.intermediate.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.intermediate.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.output.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.10.output.LayerNorm.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.query.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.query.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.key.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.key.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.value.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.self.value.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.output.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.attention.output.LayerNorm.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.intermediate.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.intermediate.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.output.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.encoder.layer.11.output.LayerNorm.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.pooler.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.pooler.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"head.1.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"head.1.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"head.4.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"head.4.bias\"</span>. \n",
       "        Unexpected <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">key</span><span style=\"font-weight: bold\">(</span>s<span style=\"font-weight: bold\">)</span> in state_dict: <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.position_ids\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.word_embeddings.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.position_embeddings.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.token_type_embeddings.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.embeddings.LayerNorm.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.query.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.query.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.key.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.key.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.value.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.0.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.1.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.2.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.3.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.4.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.5.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.6.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.7.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.8.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.query.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.query.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.key.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.key.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.value.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.self.value.bias\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.9.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.query.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.query.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.key.weight\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.key.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.value.weight\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.10.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.query.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.query.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.key.weight\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.key.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.value.weight\"</span>,\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.self.value.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.output.dense.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.output.LayerNorm.weight\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.attention.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.intermediate.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.intermediate.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.output.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.output.dense.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.output.LayerNorm.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.encoder.layer.11.output.LayerNorm.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.pooler.dense.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.model.pooler.dense.bias\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.head.1.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.head.1.bias\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"model.head.4.weight\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"model.head.4.bias\"</span>. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0mbase_model_checkpoint = \u001b[33m\"\u001b[0m\u001b[33m../baseModel/trained_model/base_model.ckpt\u001b[0m\u001b[33m\"\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mernie_model_path = \u001b[33m\"\u001b[0m\u001b[33m./models/\u001b[0m\u001b[33m\"\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 model = CombinedModel(base_model_checkpoint, ernie_model_path)                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m__init__\u001b[0m:\u001b[94m14\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load the PyTorch trained base model\u001b[0m                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m12 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.base_model = BaseClassificationModel() \u001b[2m# Initialize your base model class\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m│   │   \u001b[0mcheckpoint = torch.load(base_model_checkpoint) \u001b[2m# Load the PyTorch checkpoint\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m14 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.base_model.load_state_dict(checkpoint[\u001b[33m'\u001b[0m\u001b[33mstate_dict\u001b[0m\u001b[33m'\u001b[0m]) \u001b[2m# Load the state dict \u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Load the pre-trained ERNIE model\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/afigueroa/tfIntegration/.venv/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m2041\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mload_state_dict\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2038 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[33m'\u001b[0m\u001b[33m, \u001b[0m\u001b[33m'\u001b[0m.join(\u001b[33m'\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m'\u001b[0m.format(k) \u001b[94mfor\u001b[0m k \u001b[95min\u001b[0m missing_keys)))               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2039 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2040 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(error_msgs) > \u001b[94m0\u001b[0m:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2041 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33m'\u001b[0m\u001b[33mError(s) in loading state_dict for \u001b[0m\u001b[33m{}\u001b[0m\u001b[33m:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m{}\u001b[0m\u001b[33m'\u001b[0m.format(     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2042 \u001b[0m\u001b[2m│   │   │   │   │   │   │      \u001b[0m\u001b[96mself\u001b[0m.\u001b[91m__class__\u001b[0m.\u001b[91m__name__\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\t\u001b[0m\u001b[33m\"\u001b[0m.join(error_msgs)))         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2043 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _IncompatibleKeys(missing_keys, unexpected_keys)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2044 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0m\u001b[1;35mError\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in loading state_dict for BaseClassificationModel:\n",
       "        Missing \u001b[1;35mkey\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in state_dict: \u001b[32m\"model.embeddings.position_ids\"\u001b[0m, \u001b[32m\"model.embeddings.word_embeddings.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.embeddings.position_embeddings.weight\"\u001b[0m, \u001b[32m\"model.embeddings.token_type_embeddings.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.embeddings.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.embeddings.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.0.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.0.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.0.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.1.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.1.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.1.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.2.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.2.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.2.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.3.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.3.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.3.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.4.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.4.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.4.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.5.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.5.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.5.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.6.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.6.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.6.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.7.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.7.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.7.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.8.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.8.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.8.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.attention.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.attention.output.LayerNorm.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.encoder.layer.9.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.9.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.9.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.attention.self.query.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.output.dense.weight\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.attention.output.LayerNorm.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.intermediate.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.intermediate.dense.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.output.dense.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.10.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.10.output.LayerNorm.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.attention.self.query.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.attention.self.query.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.attention.self.key.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.attention.self.key.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.attention.self.value.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.attention.self.value.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.attention.output.dense.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.attention.output.LayerNorm.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.intermediate.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.intermediate.dense.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.output.dense.bias\"\u001b[0m, \u001b[32m\"model.encoder.layer.11.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.encoder.layer.11.output.LayerNorm.bias\"\u001b[0m, \u001b[32m\"model.pooler.dense.weight\"\u001b[0m, \u001b[32m\"model.pooler.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"head.1.weight\"\u001b[0m, \u001b[32m\"head.1.bias\"\u001b[0m, \u001b[32m\"head.4.weight\"\u001b[0m, \u001b[32m\"head.4.bias\"\u001b[0m. \n",
       "        Unexpected \u001b[1;35mkey\u001b[0m\u001b[1m(\u001b[0ms\u001b[1m)\u001b[0m in state_dict: \u001b[32m\"model.model.embeddings.position_ids\"\u001b[0m, \n",
       "\u001b[32m\"model.model.embeddings.word_embeddings.weight\"\u001b[0m, \u001b[32m\"model.model.embeddings.position_embeddings.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.embeddings.token_type_embeddings.weight\"\u001b[0m, \u001b[32m\"model.model.embeddings.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.embeddings.LayerNorm.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.attention.self.query.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.self.query.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.attention.self.key.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.self.key.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.attention.self.value.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.0.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.0.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.1.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.1.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.2.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.2.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.3.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.3.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.4.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.4.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.5.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.5.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.6.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.6.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.7.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.7.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.8.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.8.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.self.query.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.attention.self.query.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.self.key.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.attention.self.key.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.self.value.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.attention.self.value.bias\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.9.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.9.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.self.query.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.self.query.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.10.attention.self.key.weight\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.self.key.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.10.attention.self.value.weight\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.10.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.10.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.10.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.10.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.self.query.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.self.query.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.11.attention.self.key.weight\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.self.key.bias\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.11.attention.self.value.weight\"\u001b[0m,\n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.self.value.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.output.dense.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.output.LayerNorm.weight\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.attention.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.intermediate.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.11.intermediate.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.output.dense.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.11.output.dense.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.encoder.layer.11.output.LayerNorm.weight\"\u001b[0m, \u001b[32m\"model.model.encoder.layer.11.output.LayerNorm.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.model.pooler.dense.weight\"\u001b[0m, \u001b[32m\"model.model.pooler.dense.bias\"\u001b[0m, \u001b[32m\"model.head.1.weight\"\u001b[0m, \u001b[32m\"model.head.1.bias\"\u001b[0m, \n",
       "\u001b[32m\"model.head.4.weight\"\u001b[0m, \u001b[32m\"model.head.4.bias\"\u001b[0m. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_checkpoint = \"../baseModel/trained_model/base_model.ckpt\"\n",
    "ernie_model_path = \"./models/\"\n",
    "model = CombinedModel(base_model_checkpoint, ernie_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8916e28-1d4a-4d29-b361-b05d17bffed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
